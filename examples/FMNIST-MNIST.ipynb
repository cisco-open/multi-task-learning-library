{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMTL Usage Example\n",
    "This notebook shows an example of how we can use EMTL to study the training of a multi-task model on MNIST and Fashion-MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the project directory here to find the emtl package\n",
    "import os, sys\n",
    "project_dir = os.path.abspath('..')\n",
    "\n",
    "# if the kernel wasn't restarted, the folder might still be there\n",
    "if project_dir not in sys.path: \n",
    "    sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets as D\n",
    "\n",
    "# EMTL Library Imports\n",
    "from emtl import SimpleTask, Trainer\n",
    "from emtl.algorithms import SequentialTraining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "Here are defined the models we will use for this example. We are looking at a LeNet5 model from Yann LeCun, which we split into two submodules: one containing the *convolutions* (our encoder / backbone), and one with the full connections (specialized head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetConvolutions(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetConvolutions, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions\n",
    "        out = self.cnn1(x)\n",
    "        out = self.cnn2(out)\n",
    "\n",
    "        # flatten\n",
    "        out = self.flatten(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LeNetFullConnections(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetFullConnections, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(400, 120), nn.ReLU(),\n",
    "            nn.Linear(120, 84), nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, **_):\n",
    "        return self.model(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "We create two datasets: MNIST and Fashion-MNIST, each split in train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 8,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((32,32)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "\n",
    "# Datsets\n",
    "MNIST_trainset = D.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "MNIST_testset = D.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "FMNIST_trainset = D.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "FMNIST_testset = D.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_acc(k, pred, true):\n",
    "    # get indices of k highest values along last axis\n",
    "    kbest = pred.argsort(-1)[:,-k:]\n",
    "\n",
    "    # find any matches along last axis (expanding the labels to match the shape)\n",
    "    bool_matches = torch.eq(true[:, None], kbest).any(dim=-1)\n",
    "\n",
    "    # return the mean\n",
    "    return bool_matches.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_task = SimpleTask(\n",
    "    name = 'MNIST',\n",
    "    head = LeNetFullConnections(),\n",
    "    trainset = MNIST_trainset, \n",
    "    testset = MNIST_testset,\n",
    "    dataloader_params=dataset_params,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    optimizer_fn = torch.optim.Adam,\n",
    "    metric_fns = {\n",
    "        'accuracy': lambda pred, true : top_k_acc(1, pred, true),\n",
    "        'top-2 accuracy': lambda pred, true : top_k_acc(2, pred, true)\n",
    "    })\n",
    "\n",
    "FMNIST_task = SimpleTask(\n",
    "    name = 'Fashion-MNIST',\n",
    "    head = LeNetFullConnections(),\n",
    "    trainset = FMNIST_trainset, \n",
    "    testset = FMNIST_testset,\n",
    "    dataloader_params=dataset_params,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    optimizer_fn = torch.optim.Adam,\n",
    "    metric_fns = {\n",
    "        'accuracy': lambda pred, true : top_k_acc(1, pred, true),\n",
    "        'top-2 accuracy': lambda pred, true : top_k_acc(2, pred, true)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    backbone = LeNetConvolutions(),\n",
    "    tasks = [MNIST_task, FMNIST_task],\n",
    "    algorithm = SequentialTraining(epochs=3),\n",
    "    config='config.ini'\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52372b67cea419ab21537734b4cd425ac02e0aecadbd8297b2ce6404efbcdf36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
