<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>EdgeEmbedding.emtl.tasks API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>EdgeEmbedding.emtl.tasks</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from abc import ABC, abstractmethod
from collections.abc import Callable
from configparser import ConfigParser

import torch
from tqdm import tqdm

from emtl.utils import aggregate_metrics, infinite_data_batch_producer, config_file_section_to_dict


class Task(ABC):
    name: str
    trainloader: torch.utils.data.DataLoader
    testloader: torch.utils.data.DataLoader
    optimizer_fn: Callable[..., torch.optim.Optimizer]
    config: str
    device: str

    def __init__(self,
                name: str, 
                trainset: torch.utils.data.Dataset,
                testset: torch.utils.data.Dataset,
                optimizer_fn: Callable[..., torch.optim.Optimizer],
                config: str = &#39;&#39;,
                dataloader_params: dict[str, any] = {},
                optimizer_params: dict[str, any] = {},
                ) -&gt; None:
        &#39;&#39;&#39;
        Create a new basic Task.
        A task is defined by its datasets (train and test), the optimizer functions and learning 
        rate schedulers, and one or several specialized heads.

        The optimizer, and optionally a learning rate scheduler, serve to update a model&#39;s parameters
        and must not be passed as instantiated objects, but rather functions. As tasks are logically
        separated from backbones (a task only sees its specialized head), optimiers are created at
        runtime by a Trainer object.

        Data Loader params are those that define how much data to read at once, and how. These are
        passed as-is to the dataloaders that wrap the train and test datasets. One can specify things
        like batch size, number of workers, etc. 
        See https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader for more info.

        A configuration file (.INI format) may be specified too, to include dataloader, optimizer, 
        scheduler, and global parameters. When the same parameter is specified via config file and
        via method parameters, the latter take priority. For examples on how to write a config file,
        see `./configs/tasks/MNIST.ini`.

        Args:
            name (str): a friendly name for the task (can be the dataset name too)
            trainset (torch.utils.data.Dataset): dataset of train samples
            testset (torch.utils.data.Dataset): dataset of test samples
            optimizer_fn (Callable[..., torch.optim.Optimizer]): function that *produces* an optimizer
            config (str, optional): path to a configuration file, in alternative to passing 
                parameters. Defaults to &#39;&#39;.
            dataloader_params (dict[str, any], optional): paramters for the dataloader. Defaults to {}.
            optimizer_params (dict[str, any], optional): paramters for the optimizer. Defaults to {}.
        &#39;&#39;&#39;
        self.name = name
        self.optimizer_fn = optimizer_fn

        self.parse_configurations(config, dataloader_params, optimizer_params)
        self.instantiate_dataloaders(trainset, testset)
    

    def parse_configurations(self, config: str, dataloader_params: dict[str, any], 
                             optimizer_params: dict[str, any]
                             ) -&gt; None:
        &#39;&#39;&#39;
        Internal helper method to process a configuration file and method parameters.
        This method merges the (optional) configuration within the config file provided (of course,
        if any) with the method arguments passed in the function call. When parameters are duplicate,
        those passed in the method call take precedence.

        Args:
            config (str): path to a config.ini file
            dataloader_params (dict[str, any]): parameters to pass to the dataloader.
            optimizer_params (dict[str, any]): parameters to pass to the optimizer.
        &#39;&#39;&#39;
        parser = ConfigParser()
        parser.read(config)

        # default, possibly empty dictionaries
        self.dataloader_params = config_file_section_to_dict(parser, &#39;dataloader&#39;)
        self.optimizer_params  = config_file_section_to_dict(parser, &#39;optimizer&#39;)
        self.device = parser.get(&#39;global&#39;, &#39;device&#39;, fallback=&#39;cpu&#39;)

        # update values with passed arguments (as they take precedence)
        self.dataloader_params.update(dataloader_params)
        self.optimizer_params.update(optimizer_params)

        # if memory is pinned, then also enable non blocking RAM -&gt; GPU-RAM tranfers
        self.non_blocking_ops = &#39;pin_memory&#39; in self.dataloader_params and self.dataloader_params[&#39;pin_memory&#39;]


    def instantiate_dataloaders(self, trainset: torch.utils.data.Dataset, 
                                testset: torch.utils.data.Dataset) -&gt; None:
        &#39;&#39;&#39;
        Helper method to create the DataLoaders. This method will also create the train data producer.

        Args:
            trainset (torch.utils.data.Dataset): train dataset.
            testset (torch.utils.data.Dataset): test dataset.
        &#39;&#39;&#39;
        self.trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, **self.dataloader_params)
        self.testloader = torch.utils.data.DataLoader(testset, shuffle=False, **self.dataloader_params)
        self.trainproducer = infinite_data_batch_producer(self.trainloader)
        

    @abstractmethod
    def train_step(self, backbone: torch.nn.Module) -&gt; bool:
        raise NotImplementedError()
    

    @abstractmethod
    def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
        raise NotImplementedError()


    @abstractmethod
    def reset_optimizers(self):
        raise NotImplementedError()



class SimpleTask(Task):
    head: torch.nn.Module
    criterion: torch.nn.modules.loss._Loss
    optimizer: torch.optim.Optimizer
    metric_fns: dict[str, Callable[..., float]]

    def __init__(self,
                name: str, 
                head: torch.nn.Module, 
                criterion: torch.nn.modules.loss._Loss,
                metric_fns: dict[str, Callable[..., float]] = {},
                *args, **kwargs
                ) -&gt; None:
        &#39;&#39;&#39;
        Create a new Task with a single specialized head.
        At minimum, this class requires a `name`, a `trainset` and a `testset`, and an `optimizer` function.
        Refer to the documentation of the parent class`Task` for more information about these and
        other optional parameters.

        This object corresponds to a single task with a single dataset. It therefore requires a `head`
        model, a `criterion` to compute the loss, and it supports optional evaluation metrics.

        `metric_fns` is a named dictionary of functions that provide additional info
        into the accuracy of the backbone/head for a task, beyond just the loss/criterion. For
        example, one may list &#39;accuracy&#39; in a multiclass classification task, and RMSE loss too. For
        these, one would pass a dictionary as follows:
        ```
        metric_fns = {
            &#34;accuracy&#34;: lambda pred, true : (pred.argmax(1) == true).float().item(),
            &#34;rmse&#34;: lambda pred, true : torch.sqrt(nn.MSELoss()(pred, true))
        }
        ```

        Args:
            name (str): a friendly name for the task (can be the dataset name too)
            head (torch.nn.Module): model to post-process the encoder&#39;s embeddings (likely a MLP)
            criterion (torch.nn.modules.loss._Loss): function to calculate the loss
            metric_fns (dict[str, Callable[..., float]], optional): see description above. Defaults to {}.
        &#39;&#39;&#39;
        super(SimpleTask, self).__init__(name, *args, **kwargs)

        self.head = head.to(self.device, non_blocking=self.non_blocking_ops)
        self.metric_fns = metric_fns
        self.criterion = criterion
        self.reset_optimizers()

    
    def reset_optimizers(self):
        self.head_optimizer = self.optimizer_fn(self.head.parameters(), **self.optimizer_params)
        

    def train_step(self, backbone: torch.nn.Module) -&gt; tuple[bool, float]:
        &#39;&#39;&#39;
        Perform one forward and backward pass.
        This function consumes a single batch of data from the `trainproducer`, feeds it to the
        backbone and the head, calculates the loss, and does backpropagation. 

        Args:
            backbone (torch.nn.Module): backbone model to produce embeddings.
            freeze_backbone (bool): whether to stop the backbone from training (True) or update it (False).

        Returns:
            bool: whether the batch of data just processed was at the end of the train dataset.
            float: the loss of the batch
        &#39;&#39;&#39;
        (inputs, target), is_last_batch = next(self.trainproducer)
        inputs, target = inputs.to(self.device, non_blocking=self.non_blocking_ops), target.to(self.device, non_blocking=self.non_blocking_ops)

        # clear the gradients
        self.head_optimizer.zero_grad()

        # compute features, output and loss
        features = backbone(inputs)
        pred = self.head(features, original_shape = inputs.shape[-2:])
        loss = self.criterion(pred, target)
        loss.backward()
        self.head_optimizer.step()
        
        return is_last_batch, loss
    

    def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
        &#39;&#39;&#39;
        Evaluate the performance of the head and backbone on a whole dataset.

        Args:
            backbone (torch.nn.Module): the model to compute embeddings.
            set (str, optional): the dataset to evaluate on. Can be `train` or `test`. Defaults to &#39;test&#39;.

        Returns:
            dict[str, float]: named dictionary of the metrics evaluated, and the loss
        &#39;&#39;&#39;
        dataloader = self.trainloader if set == &#39;train&#39; else self.testloader
        metrics_list = []

        with torch.no_grad():
            for (inputs, target) in tqdm(dataloader, desc=self.name+&#39; eval&#39;):
                inputs, target = inputs.to(self.device, non_blocking=self.non_blocking_ops), target.to(self.device, non_blocking=self.non_blocking_ops)

                # forward pass
                features = backbone(inputs)
                pred = self.head(features, original_shape = inputs.shape[-2:])
                loss = self.criterion(pred, target)

                # evaluate metrics
                metrics_list.append({
                    **{mname:  self.metric_fns[mname](pred, target) for mname in self.metric_fns},
                    &#39;loss&#39;: loss.item()
                })
                
        return aggregate_metrics(metrics_list)



class MultiHeadedDatasetTask(Task):
    tasks_specs: list[tuple[
        str,                                # subtask name
        torch.nn.Module,                    # head model
        torch.nn.modules.loss._Loss,        # criterion
        dict[str, Callable[..., float]]     # metric_fns
    ]]
    optimizers: list[torch.optim.Optimizer]

    def __init__(self,
                name: str, 
                tasks_specs: list[tuple[
                    str, 
                    torch.nn.Module, 
                    torch.nn.modules.loss._Loss, 
                    dict[str, Callable[..., float]]]],
                *args, **kwargs) -&gt; None:
        &#39;&#39;&#39;
        Create a new Task with multiple specialized heads.
        At minimum, this class requires a `name`, a `trainset` and a `testset`, and an `optimizer` function.
        Refer to the documentation of the parent class`Task` for more information about these and
        other optional parameters. Both the trainset and the testste must return a single input data
        point (an image or a batch), and one target per each given head in the `tasks_specs`.

        This object corresponds to a collection of tasks that are based on the same dataset. For example,
        the Pascal VOC dataset can be used for both object detection and semantic segmentation. The
        advantage of using this object over creating several `SimpleTask` instances with the same
        datasets is that the *encoding* part (processing images with the backbone) is done only once
        per image for a set of tasks; then, each task&#39;s head is fed the generated embedding and optimized.
        If multiple instances of single-headed tasks are used, the backbone would have to process every
        train/test sample once per task, which is slower. From a learning perspective, the two approaches
        are equivalent: this object accumulates gradients on the backbone for each task, and then updates
        its values once at the end, with the cumulative updates from each task.

        The `tasks_specs` required parameter describes the tasks to attach to the dataset. This is
        therefore a list of specifications. Each specification is a quadruplet, with the following
        components (note that here they are named for reference, but the parameter is a tuple, not a dict):
        - `name` is the name of the specific task. For instance, one may have Pascal VOC be the name
            of the `MultiHeadedDatasetTask` object, and `Semantic Segmentation` be this task&#39;s name;
        - `head` is the model that processes the embeddings produced by the backbone for the task;
        - `criterion` is the function to compute the loss
        - `metric_fns` is a named dictionary of evaluation functions beyond the loss. See `SimpleTask`
            for a more detailed explanation and examples.

        Args:
            name (str): a friendly name for the task (can be the dataset name too)
            tasks_specs (list[
                tuple[ 
                    str, 
                    torch.nn.Module, 
                    torch.nn.modules.loss._Loss, 
                    dict[str, Callable[..., float]]
                ]]): list of heads&#39; specifications as described above
        &#39;&#39;&#39;
        super(MultiHeadedDatasetTask, self).__init__(name, *args, **kwargs)
        self.tasks_specs = []
        
        # change the list of tuples to list of dictinaries to more easily access its members
        for t_name, head, criterion, metric_fns in tasks_specs:
            head = head.to(self.device, non_blocking=self.non_blocking_ops)
            optimizer = self.optimizer_fn(head.parameters(), **self.optimizer_params)

            self.tasks_specs.append({
                &#39;name&#39;: t_name, 
                &#39;head&#39;: head,
                &#39;criterion&#39;: criterion, 
                &#39;metrics&#39;: metric_fns,
                &#39;optimizer&#39;: optimizer,
            })

    
    def reset_optimizers(self):
        for spec in self.tasks_specs:
            spec[&#39;optimizer&#39;] = self.optimizer_fn(spec[&#39;head&#39;].parameters(), **self.optimizer_params)
        

    def train_step(self, backbone: torch.nn.Module) -&gt; tuple[bool, float]:
        &#39;&#39;&#39;
        Perform one forward and backward pass.
        This function consumes a single batch of data from the `trainproducer` and feeds it to the
        backbone once to produce the embeddings.
        Then, for every head in the `task_specs`, a target is taken from the batch of data, and the
        embeddings are passed through the head, to then compare with the targets and compute the loss.
        The loss is backpropagated through the head and the backbone both. Then, the head&#39;s weights
        are updated. Once all heads have been updated, the backbone is updated with the accumulated
        gradients information.

        Args:
            backbone (torch.nn.Module): backbone model to produce embeddings.
            freeze_backbone (bool): whether to stop the backbone from training (True) or update it (False).

        Returns:
            bool: whether the batch of data just processed was at the end of the train dataset.
            float: cumulative loss for the task
        &#39;&#39;&#39;
        (inputs, targets), is_last_batch = next(self.trainproducer)
        inputs = inputs.to(self.device, non_blocking=self.non_blocking_ops)
        features = backbone(inputs)
        overall_loss = 0

        for target, task in zip(targets, self.tasks_specs):
            target = target.to(self.device, non_blocking=self.non_blocking_ops)

            # forward prop
            task[&#39;head&#39;].zero_grad()
            pred = task[&#39;head&#39;](features, original_shape=inputs.shape[-2:])

            # compute and accumulate loss
            loss = task[&#39;criterion&#39;](pred, target)
            overall_loss = overall_loss + loss

        # compute all gradients
        overall_loss.backward()

        # update the heads&#39; weights
        for task in self.tasks_specs:
            task[&#39;optimizer&#39;].step()
        
        return is_last_batch, overall_loss
    

    def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
        &#39;&#39;&#39;
        Evaluate the performance of the backbone and all the heads on a whole dataset.
        This method produces a named dictionary of metrics, based on the supplied `metric_fns`
        dictionaries in each `task_spec`. The produced dictionary contains a key for every task-metric
        pair, for instance a `task_specs` with a task named `bbox` and another task named `features`,
        the latter with a `metric_fns` dictionary with a metric called `precision`, will produce a 
        dictionary with keys `[&#39;bbox loss&#39;, &#39;features precision&#39;, &#39;features loss&#39;]`. 

        Args:
            backbone (torch.nn.Module): the model to compute embeddings.
            set (str, optional): the dataset to evaluate on. Can be `train` or `test`. Defaults to &#39;test&#39;.

        Returns:
            dict[str, float]: named dictionary of the metrics evaluated, and the loss, for each task.
        &#39;&#39;&#39;
        dataloader = self.trainloader if set == &#39;train&#39; else self.testloader
        metrics_list = []

        with torch.no_grad():
            for (inputs, targets) in tqdm(dataloader, desc=self.name+&#39; eval&#39;):
                features = backbone(inputs.to(self.device, non_blocking=self.non_blocking_ops))

                for target, task in zip(targets, self.tasks_specs):
                    target = target.to(self.device, non_blocking=self.non_blocking_ops)

                    # forward pass
                    pred = task[&#39;head&#39;](features, original_shape = inputs.shape[-2:])
                    loss = task[&#39;criterion&#39;](pred, target)

                    # evaluate metrics
                    metric_fns = task[&#39;metrics&#39;]
                    tname = task[&#39;name&#39;]

                    metrics_list.append({
                        **{f&#39;{tname} {mname}&#39;:  metric_fns[mname](pred, target) for mname in metric_fns},
                        f&#39;{tname} loss&#39;: loss.item()
                    })
        
        return aggregate_metrics(metrics_list)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask"><code class="flex name class">
<span>class <span class="ident">MultiHeadedDatasetTask</span></span>
<span>(</span><span>name: str, tasks_specs: list[tuple[str, torch.nn.modules.module.Module, torch.nn.modules.loss._Loss, dict[str, collections.abc.Callable[..., float]]]], *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create a new Task with multiple specialized heads.
At minimum, this class requires a <code>name</code>, a <code>trainset</code> and a <code>testset</code>, and an <code>optimizer</code> function.
Refer to the documentation of the parent class<code><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></code> for more information about these and
other optional parameters. Both the trainset and the testste must return a single input data
point (an image or a batch), and one target per each given head in the <code>tasks_specs</code>.</p>
<p>This object corresponds to a collection of tasks that are based on the same dataset. For example,
the Pascal VOC dataset can be used for both object detection and semantic segmentation. The
advantage of using this object over creating several <code><a title="EdgeEmbedding.emtl.tasks.SimpleTask" href="#EdgeEmbedding.emtl.tasks.SimpleTask">SimpleTask</a></code> instances with the same
datasets is that the <em>encoding</em> part (processing images with the backbone) is done only once
per image for a set of tasks; then, each task's head is fed the generated embedding and optimized.
If multiple instances of single-headed tasks are used, the backbone would have to process every
train/test sample once per task, which is slower. From a learning perspective, the two approaches
are equivalent: this object accumulates gradients on the backbone for each task, and then updates
its values once at the end, with the cumulative updates from each task.</p>
<p>The <code>tasks_specs</code> required parameter describes the tasks to attach to the dataset. This is
therefore a list of specifications. Each specification is a quadruplet, with the following
components (note that here they are named for reference, but the parameter is a tuple, not a dict):
- <code>name</code> is the name of the specific task. For instance, one may have Pascal VOC be the name
of the <code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask">MultiHeadedDatasetTask</a></code> object, and <code>Semantic Segmentation</code> be this task's name;
- <code>head</code> is the model that processes the embeddings produced by the backbone for the task;
- <code>criterion</code> is the function to compute the loss
- <code>metric_fns</code> is a named dictionary of evaluation functions beyond the loss. See <code><a title="EdgeEmbedding.emtl.tasks.SimpleTask" href="#EdgeEmbedding.emtl.tasks.SimpleTask">SimpleTask</a></code>
for a more detailed explanation and examples.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>a friendly name for the task (can be the dataset name too)</dd>
</dl>
<p>tasks_specs (list[
tuple[
str,
torch.nn.Module,
torch.nn.modules.loss._Loss,
dict[str, Callable[&hellip;, float]]
]]): list of heads' specifications as described above</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MultiHeadedDatasetTask(Task):
    tasks_specs: list[tuple[
        str,                                # subtask name
        torch.nn.Module,                    # head model
        torch.nn.modules.loss._Loss,        # criterion
        dict[str, Callable[..., float]]     # metric_fns
    ]]
    optimizers: list[torch.optim.Optimizer]

    def __init__(self,
                name: str, 
                tasks_specs: list[tuple[
                    str, 
                    torch.nn.Module, 
                    torch.nn.modules.loss._Loss, 
                    dict[str, Callable[..., float]]]],
                *args, **kwargs) -&gt; None:
        &#39;&#39;&#39;
        Create a new Task with multiple specialized heads.
        At minimum, this class requires a `name`, a `trainset` and a `testset`, and an `optimizer` function.
        Refer to the documentation of the parent class`Task` for more information about these and
        other optional parameters. Both the trainset and the testste must return a single input data
        point (an image or a batch), and one target per each given head in the `tasks_specs`.

        This object corresponds to a collection of tasks that are based on the same dataset. For example,
        the Pascal VOC dataset can be used for both object detection and semantic segmentation. The
        advantage of using this object over creating several `SimpleTask` instances with the same
        datasets is that the *encoding* part (processing images with the backbone) is done only once
        per image for a set of tasks; then, each task&#39;s head is fed the generated embedding and optimized.
        If multiple instances of single-headed tasks are used, the backbone would have to process every
        train/test sample once per task, which is slower. From a learning perspective, the two approaches
        are equivalent: this object accumulates gradients on the backbone for each task, and then updates
        its values once at the end, with the cumulative updates from each task.

        The `tasks_specs` required parameter describes the tasks to attach to the dataset. This is
        therefore a list of specifications. Each specification is a quadruplet, with the following
        components (note that here they are named for reference, but the parameter is a tuple, not a dict):
        - `name` is the name of the specific task. For instance, one may have Pascal VOC be the name
            of the `MultiHeadedDatasetTask` object, and `Semantic Segmentation` be this task&#39;s name;
        - `head` is the model that processes the embeddings produced by the backbone for the task;
        - `criterion` is the function to compute the loss
        - `metric_fns` is a named dictionary of evaluation functions beyond the loss. See `SimpleTask`
            for a more detailed explanation and examples.

        Args:
            name (str): a friendly name for the task (can be the dataset name too)
            tasks_specs (list[
                tuple[ 
                    str, 
                    torch.nn.Module, 
                    torch.nn.modules.loss._Loss, 
                    dict[str, Callable[..., float]]
                ]]): list of heads&#39; specifications as described above
        &#39;&#39;&#39;
        super(MultiHeadedDatasetTask, self).__init__(name, *args, **kwargs)
        self.tasks_specs = []
        
        # change the list of tuples to list of dictinaries to more easily access its members
        for t_name, head, criterion, metric_fns in tasks_specs:
            head = head.to(self.device, non_blocking=self.non_blocking_ops)
            optimizer = self.optimizer_fn(head.parameters(), **self.optimizer_params)

            self.tasks_specs.append({
                &#39;name&#39;: t_name, 
                &#39;head&#39;: head,
                &#39;criterion&#39;: criterion, 
                &#39;metrics&#39;: metric_fns,
                &#39;optimizer&#39;: optimizer,
            })

    
    def reset_optimizers(self):
        for spec in self.tasks_specs:
            spec[&#39;optimizer&#39;] = self.optimizer_fn(spec[&#39;head&#39;].parameters(), **self.optimizer_params)
        

    def train_step(self, backbone: torch.nn.Module) -&gt; tuple[bool, float]:
        &#39;&#39;&#39;
        Perform one forward and backward pass.
        This function consumes a single batch of data from the `trainproducer` and feeds it to the
        backbone once to produce the embeddings.
        Then, for every head in the `task_specs`, a target is taken from the batch of data, and the
        embeddings are passed through the head, to then compare with the targets and compute the loss.
        The loss is backpropagated through the head and the backbone both. Then, the head&#39;s weights
        are updated. Once all heads have been updated, the backbone is updated with the accumulated
        gradients information.

        Args:
            backbone (torch.nn.Module): backbone model to produce embeddings.
            freeze_backbone (bool): whether to stop the backbone from training (True) or update it (False).

        Returns:
            bool: whether the batch of data just processed was at the end of the train dataset.
            float: cumulative loss for the task
        &#39;&#39;&#39;
        (inputs, targets), is_last_batch = next(self.trainproducer)
        inputs = inputs.to(self.device, non_blocking=self.non_blocking_ops)
        features = backbone(inputs)
        overall_loss = 0

        for target, task in zip(targets, self.tasks_specs):
            target = target.to(self.device, non_blocking=self.non_blocking_ops)

            # forward prop
            task[&#39;head&#39;].zero_grad()
            pred = task[&#39;head&#39;](features, original_shape=inputs.shape[-2:])

            # compute and accumulate loss
            loss = task[&#39;criterion&#39;](pred, target)
            overall_loss = overall_loss + loss

        # compute all gradients
        overall_loss.backward()

        # update the heads&#39; weights
        for task in self.tasks_specs:
            task[&#39;optimizer&#39;].step()
        
        return is_last_batch, overall_loss
    

    def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
        &#39;&#39;&#39;
        Evaluate the performance of the backbone and all the heads on a whole dataset.
        This method produces a named dictionary of metrics, based on the supplied `metric_fns`
        dictionaries in each `task_spec`. The produced dictionary contains a key for every task-metric
        pair, for instance a `task_specs` with a task named `bbox` and another task named `features`,
        the latter with a `metric_fns` dictionary with a metric called `precision`, will produce a 
        dictionary with keys `[&#39;bbox loss&#39;, &#39;features precision&#39;, &#39;features loss&#39;]`. 

        Args:
            backbone (torch.nn.Module): the model to compute embeddings.
            set (str, optional): the dataset to evaluate on. Can be `train` or `test`. Defaults to &#39;test&#39;.

        Returns:
            dict[str, float]: named dictionary of the metrics evaluated, and the loss, for each task.
        &#39;&#39;&#39;
        dataloader = self.trainloader if set == &#39;train&#39; else self.testloader
        metrics_list = []

        with torch.no_grad():
            for (inputs, targets) in tqdm(dataloader, desc=self.name+&#39; eval&#39;):
                features = backbone(inputs.to(self.device, non_blocking=self.non_blocking_ops))

                for target, task in zip(targets, self.tasks_specs):
                    target = target.to(self.device, non_blocking=self.non_blocking_ops)

                    # forward pass
                    pred = task[&#39;head&#39;](features, original_shape = inputs.shape[-2:])
                    loss = task[&#39;criterion&#39;](pred, target)

                    # evaluate metrics
                    metric_fns = task[&#39;metrics&#39;]
                    tname = task[&#39;name&#39;]

                    metrics_list.append({
                        **{f&#39;{tname} {mname}&#39;:  metric_fns[mname](pred, target) for mname in metric_fns},
                        f&#39;{tname} loss&#39;: loss.item()
                    })
        
        return aggregate_metrics(metrics_list)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.optimizers"><code class="name">var <span class="ident">optimizers</span> : list[torch.optim.optimizer.Optimizer]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.tasks_specs"><code class="name">var <span class="ident">tasks_specs</span> : list[tuple[str, torch.nn.modules.module.Module, torch.nn.modules.loss._Loss, dict[str, collections.abc.Callable[..., float]]]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self, backbone: torch.nn.modules.module.Module, set: str = 'test') ‑> dict[str, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the performance of the backbone and all the heads on a whole dataset.
This method produces a named dictionary of metrics, based on the supplied <code>metric_fns</code>
dictionaries in each <code>task_spec</code>. The produced dictionary contains a key for every task-metric
pair, for instance a <code>task_specs</code> with a task named <code>bbox</code> and another task named <code>features</code>,
the latter with a <code>metric_fns</code> dictionary with a metric called <code>precision</code>, will produce a
dictionary with keys <code>['bbox loss', 'features precision', 'features loss']</code>. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>backbone</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>the model to compute embeddings.</dd>
<dt><strong><code>set</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>the dataset to evaluate on. Can be <code>train</code> or <code>test</code>. Defaults to 'test'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict[str, float]</code></dt>
<dd>named dictionary of the metrics evaluated, and the loss, for each task.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
    &#39;&#39;&#39;
    Evaluate the performance of the backbone and all the heads on a whole dataset.
    This method produces a named dictionary of metrics, based on the supplied `metric_fns`
    dictionaries in each `task_spec`. The produced dictionary contains a key for every task-metric
    pair, for instance a `task_specs` with a task named `bbox` and another task named `features`,
    the latter with a `metric_fns` dictionary with a metric called `precision`, will produce a 
    dictionary with keys `[&#39;bbox loss&#39;, &#39;features precision&#39;, &#39;features loss&#39;]`. 

    Args:
        backbone (torch.nn.Module): the model to compute embeddings.
        set (str, optional): the dataset to evaluate on. Can be `train` or `test`. Defaults to &#39;test&#39;.

    Returns:
        dict[str, float]: named dictionary of the metrics evaluated, and the loss, for each task.
    &#39;&#39;&#39;
    dataloader = self.trainloader if set == &#39;train&#39; else self.testloader
    metrics_list = []

    with torch.no_grad():
        for (inputs, targets) in tqdm(dataloader, desc=self.name+&#39; eval&#39;):
            features = backbone(inputs.to(self.device, non_blocking=self.non_blocking_ops))

            for target, task in zip(targets, self.tasks_specs):
                target = target.to(self.device, non_blocking=self.non_blocking_ops)

                # forward pass
                pred = task[&#39;head&#39;](features, original_shape = inputs.shape[-2:])
                loss = task[&#39;criterion&#39;](pred, target)

                # evaluate metrics
                metric_fns = task[&#39;metrics&#39;]
                tname = task[&#39;name&#39;]

                metrics_list.append({
                    **{f&#39;{tname} {mname}&#39;:  metric_fns[mname](pred, target) for mname in metric_fns},
                    f&#39;{tname} loss&#39;: loss.item()
                })
    
    return aggregate_metrics(metrics_list)</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.reset_optimizers"><code class="name flex">
<span>def <span class="ident">reset_optimizers</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_optimizers(self):
    for spec in self.tasks_specs:
        spec[&#39;optimizer&#39;] = self.optimizer_fn(spec[&#39;head&#39;].parameters(), **self.optimizer_params)</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.train_step"><code class="name flex">
<span>def <span class="ident">train_step</span></span>(<span>self, backbone: torch.nn.modules.module.Module) ‑> tuple[bool, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Perform one forward and backward pass.
This function consumes a single batch of data from the <code>trainproducer</code> and feeds it to the
backbone once to produce the embeddings.
Then, for every head in the <code>task_specs</code>, a target is taken from the batch of data, and the
embeddings are passed through the head, to then compare with the targets and compute the loss.
The loss is backpropagated through the head and the backbone both. Then, the head's weights
are updated. Once all heads have been updated, the backbone is updated with the accumulated
gradients information.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>backbone</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>backbone model to produce embeddings.</dd>
<dt><strong><code>freeze_backbone</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether to stop the backbone from training (True) or update it (False).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>whether the batch of data just processed was at the end of the train dataset.</dd>
<dt><code>float</code></dt>
<dd>cumulative loss for the task</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_step(self, backbone: torch.nn.Module) -&gt; tuple[bool, float]:
    &#39;&#39;&#39;
    Perform one forward and backward pass.
    This function consumes a single batch of data from the `trainproducer` and feeds it to the
    backbone once to produce the embeddings.
    Then, for every head in the `task_specs`, a target is taken from the batch of data, and the
    embeddings are passed through the head, to then compare with the targets and compute the loss.
    The loss is backpropagated through the head and the backbone both. Then, the head&#39;s weights
    are updated. Once all heads have been updated, the backbone is updated with the accumulated
    gradients information.

    Args:
        backbone (torch.nn.Module): backbone model to produce embeddings.
        freeze_backbone (bool): whether to stop the backbone from training (True) or update it (False).

    Returns:
        bool: whether the batch of data just processed was at the end of the train dataset.
        float: cumulative loss for the task
    &#39;&#39;&#39;
    (inputs, targets), is_last_batch = next(self.trainproducer)
    inputs = inputs.to(self.device, non_blocking=self.non_blocking_ops)
    features = backbone(inputs)
    overall_loss = 0

    for target, task in zip(targets, self.tasks_specs):
        target = target.to(self.device, non_blocking=self.non_blocking_ops)

        # forward prop
        task[&#39;head&#39;].zero_grad()
        pred = task[&#39;head&#39;](features, original_shape=inputs.shape[-2:])

        # compute and accumulate loss
        loss = task[&#39;criterion&#39;](pred, target)
        overall_loss = overall_loss + loss

    # compute all gradients
    overall_loss.backward()

    # update the heads&#39; weights
    for task in self.tasks_specs:
        task[&#39;optimizer&#39;].step()
    
    return is_last_batch, overall_loss</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></b></code>:
<ul class="hlist">
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders" href="#EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders">instantiate_dataloaders</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.parse_configurations" href="#EdgeEmbedding.emtl.tasks.Task.parse_configurations">parse_configurations</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask"><code class="flex name class">
<span>class <span class="ident">SimpleTask</span></span>
<span>(</span><span>name: str, head: torch.nn.modules.module.Module, criterion: torch.nn.modules.loss._Loss, metric_fns: dict[str, collections.abc.Callable[..., float]] = {}, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create a new Task with a single specialized head.
At minimum, this class requires a <code>name</code>, a <code>trainset</code> and a <code>testset</code>, and an <code>optimizer</code> function.
Refer to the documentation of the parent class<code><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></code> for more information about these and
other optional parameters.</p>
<p>This object corresponds to a single task with a single dataset. It therefore requires a <code>head</code>
model, a <code>criterion</code> to compute the loss, and it supports optional evaluation metrics.</p>
<p><code>metric_fns</code> is a named dictionary of functions that provide additional info
into the accuracy of the backbone/head for a task, beyond just the loss/criterion. For
example, one may list 'accuracy' in a multiclass classification task, and RMSE loss too. For
these, one would pass a dictionary as follows:</p>
<pre><code>metric_fns = {
    &quot;accuracy&quot;: lambda pred, true : (pred.argmax(1) == true).float().item(),
    &quot;rmse&quot;: lambda pred, true : torch.sqrt(nn.MSELoss()(pred, true))
}
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>a friendly name for the task (can be the dataset name too)</dd>
<dt><strong><code>head</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>model to post-process the encoder's embeddings (likely a MLP)</dd>
<dt><strong><code>criterion</code></strong> :&ensp;<code>torch.nn.modules.loss._Loss</code></dt>
<dd>function to calculate the loss</dd>
<dt><strong><code>metric_fns</code></strong> :&ensp;<code>dict[str, Callable[&hellip;, float]]</code>, optional</dt>
<dd>see description above. Defaults to {}.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleTask(Task):
    head: torch.nn.Module
    criterion: torch.nn.modules.loss._Loss
    optimizer: torch.optim.Optimizer
    metric_fns: dict[str, Callable[..., float]]

    def __init__(self,
                name: str, 
                head: torch.nn.Module, 
                criterion: torch.nn.modules.loss._Loss,
                metric_fns: dict[str, Callable[..., float]] = {},
                *args, **kwargs
                ) -&gt; None:
        &#39;&#39;&#39;
        Create a new Task with a single specialized head.
        At minimum, this class requires a `name`, a `trainset` and a `testset`, and an `optimizer` function.
        Refer to the documentation of the parent class`Task` for more information about these and
        other optional parameters.

        This object corresponds to a single task with a single dataset. It therefore requires a `head`
        model, a `criterion` to compute the loss, and it supports optional evaluation metrics.

        `metric_fns` is a named dictionary of functions that provide additional info
        into the accuracy of the backbone/head for a task, beyond just the loss/criterion. For
        example, one may list &#39;accuracy&#39; in a multiclass classification task, and RMSE loss too. For
        these, one would pass a dictionary as follows:
        ```
        metric_fns = {
            &#34;accuracy&#34;: lambda pred, true : (pred.argmax(1) == true).float().item(),
            &#34;rmse&#34;: lambda pred, true : torch.sqrt(nn.MSELoss()(pred, true))
        }
        ```

        Args:
            name (str): a friendly name for the task (can be the dataset name too)
            head (torch.nn.Module): model to post-process the encoder&#39;s embeddings (likely a MLP)
            criterion (torch.nn.modules.loss._Loss): function to calculate the loss
            metric_fns (dict[str, Callable[..., float]], optional): see description above. Defaults to {}.
        &#39;&#39;&#39;
        super(SimpleTask, self).__init__(name, *args, **kwargs)

        self.head = head.to(self.device, non_blocking=self.non_blocking_ops)
        self.metric_fns = metric_fns
        self.criterion = criterion
        self.reset_optimizers()

    
    def reset_optimizers(self):
        self.head_optimizer = self.optimizer_fn(self.head.parameters(), **self.optimizer_params)
        

    def train_step(self, backbone: torch.nn.Module) -&gt; tuple[bool, float]:
        &#39;&#39;&#39;
        Perform one forward and backward pass.
        This function consumes a single batch of data from the `trainproducer`, feeds it to the
        backbone and the head, calculates the loss, and does backpropagation. 

        Args:
            backbone (torch.nn.Module): backbone model to produce embeddings.
            freeze_backbone (bool): whether to stop the backbone from training (True) or update it (False).

        Returns:
            bool: whether the batch of data just processed was at the end of the train dataset.
            float: the loss of the batch
        &#39;&#39;&#39;
        (inputs, target), is_last_batch = next(self.trainproducer)
        inputs, target = inputs.to(self.device, non_blocking=self.non_blocking_ops), target.to(self.device, non_blocking=self.non_blocking_ops)

        # clear the gradients
        self.head_optimizer.zero_grad()

        # compute features, output and loss
        features = backbone(inputs)
        pred = self.head(features, original_shape = inputs.shape[-2:])
        loss = self.criterion(pred, target)
        loss.backward()
        self.head_optimizer.step()
        
        return is_last_batch, loss
    

    def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
        &#39;&#39;&#39;
        Evaluate the performance of the head and backbone on a whole dataset.

        Args:
            backbone (torch.nn.Module): the model to compute embeddings.
            set (str, optional): the dataset to evaluate on. Can be `train` or `test`. Defaults to &#39;test&#39;.

        Returns:
            dict[str, float]: named dictionary of the metrics evaluated, and the loss
        &#39;&#39;&#39;
        dataloader = self.trainloader if set == &#39;train&#39; else self.testloader
        metrics_list = []

        with torch.no_grad():
            for (inputs, target) in tqdm(dataloader, desc=self.name+&#39; eval&#39;):
                inputs, target = inputs.to(self.device, non_blocking=self.non_blocking_ops), target.to(self.device, non_blocking=self.non_blocking_ops)

                # forward pass
                features = backbone(inputs)
                pred = self.head(features, original_shape = inputs.shape[-2:])
                loss = self.criterion(pred, target)

                # evaluate metrics
                metrics_list.append({
                    **{mname:  self.metric_fns[mname](pred, target) for mname in self.metric_fns},
                    &#39;loss&#39;: loss.item()
                })
                
        return aggregate_metrics(metrics_list)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.criterion"><code class="name">var <span class="ident">criterion</span> : torch.nn.modules.loss._Loss</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.head"><code class="name">var <span class="ident">head</span> : torch.nn.modules.module.Module</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.metric_fns"><code class="name">var <span class="ident">metric_fns</span> : dict[str, collections.abc.Callable[..., float]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.optimizer"><code class="name">var <span class="ident">optimizer</span> : torch.optim.optimizer.Optimizer</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self, backbone: torch.nn.modules.module.Module, set: str = 'test') ‑> dict[str, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the performance of the head and backbone on a whole dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>backbone</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>the model to compute embeddings.</dd>
<dt><strong><code>set</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>the dataset to evaluate on. Can be <code>train</code> or <code>test</code>. Defaults to 'test'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict[str, float]</code></dt>
<dd>named dictionary of the metrics evaluated, and the loss</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
    &#39;&#39;&#39;
    Evaluate the performance of the head and backbone on a whole dataset.

    Args:
        backbone (torch.nn.Module): the model to compute embeddings.
        set (str, optional): the dataset to evaluate on. Can be `train` or `test`. Defaults to &#39;test&#39;.

    Returns:
        dict[str, float]: named dictionary of the metrics evaluated, and the loss
    &#39;&#39;&#39;
    dataloader = self.trainloader if set == &#39;train&#39; else self.testloader
    metrics_list = []

    with torch.no_grad():
        for (inputs, target) in tqdm(dataloader, desc=self.name+&#39; eval&#39;):
            inputs, target = inputs.to(self.device, non_blocking=self.non_blocking_ops), target.to(self.device, non_blocking=self.non_blocking_ops)

            # forward pass
            features = backbone(inputs)
            pred = self.head(features, original_shape = inputs.shape[-2:])
            loss = self.criterion(pred, target)

            # evaluate metrics
            metrics_list.append({
                **{mname:  self.metric_fns[mname](pred, target) for mname in self.metric_fns},
                &#39;loss&#39;: loss.item()
            })
            
    return aggregate_metrics(metrics_list)</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.reset_optimizers"><code class="name flex">
<span>def <span class="ident">reset_optimizers</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_optimizers(self):
    self.head_optimizer = self.optimizer_fn(self.head.parameters(), **self.optimizer_params)</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.SimpleTask.train_step"><code class="name flex">
<span>def <span class="ident">train_step</span></span>(<span>self, backbone: torch.nn.modules.module.Module) ‑> tuple[bool, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Perform one forward and backward pass.
This function consumes a single batch of data from the <code>trainproducer</code>, feeds it to the
backbone and the head, calculates the loss, and does backpropagation. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>backbone</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>backbone model to produce embeddings.</dd>
<dt><strong><code>freeze_backbone</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether to stop the backbone from training (True) or update it (False).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>whether the batch of data just processed was at the end of the train dataset.</dd>
<dt><code>float</code></dt>
<dd>the loss of the batch</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_step(self, backbone: torch.nn.Module) -&gt; tuple[bool, float]:
    &#39;&#39;&#39;
    Perform one forward and backward pass.
    This function consumes a single batch of data from the `trainproducer`, feeds it to the
    backbone and the head, calculates the loss, and does backpropagation. 

    Args:
        backbone (torch.nn.Module): backbone model to produce embeddings.
        freeze_backbone (bool): whether to stop the backbone from training (True) or update it (False).

    Returns:
        bool: whether the batch of data just processed was at the end of the train dataset.
        float: the loss of the batch
    &#39;&#39;&#39;
    (inputs, target), is_last_batch = next(self.trainproducer)
    inputs, target = inputs.to(self.device, non_blocking=self.non_blocking_ops), target.to(self.device, non_blocking=self.non_blocking_ops)

    # clear the gradients
    self.head_optimizer.zero_grad()

    # compute features, output and loss
    features = backbone(inputs)
    pred = self.head(features, original_shape = inputs.shape[-2:])
    loss = self.criterion(pred, target)
    loss.backward()
    self.head_optimizer.step()
    
    return is_last_batch, loss</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></b></code>:
<ul class="hlist">
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders" href="#EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders">instantiate_dataloaders</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.parse_configurations" href="#EdgeEmbedding.emtl.tasks.Task.parse_configurations">parse_configurations</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task"><code class="flex name class">
<span>class <span class="ident">Task</span></span>
<span>(</span><span>name: str, trainset: torch.utils.data.dataset.Dataset, testset: torch.utils.data.dataset.Dataset, optimizer_fn: collections.abc.Callable[..., torch.optim.optimizer.Optimizer], config: str = '', dataloader_params: dict[str, any] = {}, optimizer_params: dict[str, any] = {})</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create a new basic Task.
A task is defined by its datasets (train and test), the optimizer functions and learning
rate schedulers, and one or several specialized heads.</p>
<p>The optimizer, and optionally a learning rate scheduler, serve to update a model's parameters
and must not be passed as instantiated objects, but rather functions. As tasks are logically
separated from backbones (a task only sees its specialized head), optimiers are created at
runtime by a Trainer object.</p>
<p>Data Loader params are those that define how much data to read at once, and how. These are
passed as-is to the dataloaders that wrap the train and test datasets. One can specify things
like batch size, number of workers, etc.
See <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</a> for more info.</p>
<p>A configuration file (.INI format) may be specified too, to include dataloader, optimizer,
scheduler, and global parameters. When the same parameter is specified via config file and
via method parameters, the latter take priority. For examples on how to write a config file,
see <code>./configs/tasks/MNIST.ini</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>a friendly name for the task (can be the dataset name too)</dd>
<dt><strong><code>trainset</code></strong> :&ensp;<code>torch.utils.data.Dataset</code></dt>
<dd>dataset of train samples</dd>
<dt><strong><code>testset</code></strong> :&ensp;<code>torch.utils.data.Dataset</code></dt>
<dd>dataset of test samples</dd>
<dt><strong><code>optimizer_fn</code></strong> :&ensp;<code>Callable[&hellip;, torch.optim.Optimizer]</code></dt>
<dd>function that <em>produces</em> an optimizer</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>path to a configuration file, in alternative to passing
parameters. Defaults to ''.</dd>
<dt><strong><code>dataloader_params</code></strong> :&ensp;<code>dict[str, any]</code>, optional</dt>
<dd>paramters for the dataloader. Defaults to {}.</dd>
<dt><strong><code>optimizer_params</code></strong> :&ensp;<code>dict[str, any]</code>, optional</dt>
<dd>paramters for the optimizer. Defaults to {}.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Task(ABC):
    name: str
    trainloader: torch.utils.data.DataLoader
    testloader: torch.utils.data.DataLoader
    optimizer_fn: Callable[..., torch.optim.Optimizer]
    config: str
    device: str

    def __init__(self,
                name: str, 
                trainset: torch.utils.data.Dataset,
                testset: torch.utils.data.Dataset,
                optimizer_fn: Callable[..., torch.optim.Optimizer],
                config: str = &#39;&#39;,
                dataloader_params: dict[str, any] = {},
                optimizer_params: dict[str, any] = {},
                ) -&gt; None:
        &#39;&#39;&#39;
        Create a new basic Task.
        A task is defined by its datasets (train and test), the optimizer functions and learning 
        rate schedulers, and one or several specialized heads.

        The optimizer, and optionally a learning rate scheduler, serve to update a model&#39;s parameters
        and must not be passed as instantiated objects, but rather functions. As tasks are logically
        separated from backbones (a task only sees its specialized head), optimiers are created at
        runtime by a Trainer object.

        Data Loader params are those that define how much data to read at once, and how. These are
        passed as-is to the dataloaders that wrap the train and test datasets. One can specify things
        like batch size, number of workers, etc. 
        See https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader for more info.

        A configuration file (.INI format) may be specified too, to include dataloader, optimizer, 
        scheduler, and global parameters. When the same parameter is specified via config file and
        via method parameters, the latter take priority. For examples on how to write a config file,
        see `./configs/tasks/MNIST.ini`.

        Args:
            name (str): a friendly name for the task (can be the dataset name too)
            trainset (torch.utils.data.Dataset): dataset of train samples
            testset (torch.utils.data.Dataset): dataset of test samples
            optimizer_fn (Callable[..., torch.optim.Optimizer]): function that *produces* an optimizer
            config (str, optional): path to a configuration file, in alternative to passing 
                parameters. Defaults to &#39;&#39;.
            dataloader_params (dict[str, any], optional): paramters for the dataloader. Defaults to {}.
            optimizer_params (dict[str, any], optional): paramters for the optimizer. Defaults to {}.
        &#39;&#39;&#39;
        self.name = name
        self.optimizer_fn = optimizer_fn

        self.parse_configurations(config, dataloader_params, optimizer_params)
        self.instantiate_dataloaders(trainset, testset)
    

    def parse_configurations(self, config: str, dataloader_params: dict[str, any], 
                             optimizer_params: dict[str, any]
                             ) -&gt; None:
        &#39;&#39;&#39;
        Internal helper method to process a configuration file and method parameters.
        This method merges the (optional) configuration within the config file provided (of course,
        if any) with the method arguments passed in the function call. When parameters are duplicate,
        those passed in the method call take precedence.

        Args:
            config (str): path to a config.ini file
            dataloader_params (dict[str, any]): parameters to pass to the dataloader.
            optimizer_params (dict[str, any]): parameters to pass to the optimizer.
        &#39;&#39;&#39;
        parser = ConfigParser()
        parser.read(config)

        # default, possibly empty dictionaries
        self.dataloader_params = config_file_section_to_dict(parser, &#39;dataloader&#39;)
        self.optimizer_params  = config_file_section_to_dict(parser, &#39;optimizer&#39;)
        self.device = parser.get(&#39;global&#39;, &#39;device&#39;, fallback=&#39;cpu&#39;)

        # update values with passed arguments (as they take precedence)
        self.dataloader_params.update(dataloader_params)
        self.optimizer_params.update(optimizer_params)

        # if memory is pinned, then also enable non blocking RAM -&gt; GPU-RAM tranfers
        self.non_blocking_ops = &#39;pin_memory&#39; in self.dataloader_params and self.dataloader_params[&#39;pin_memory&#39;]


    def instantiate_dataloaders(self, trainset: torch.utils.data.Dataset, 
                                testset: torch.utils.data.Dataset) -&gt; None:
        &#39;&#39;&#39;
        Helper method to create the DataLoaders. This method will also create the train data producer.

        Args:
            trainset (torch.utils.data.Dataset): train dataset.
            testset (torch.utils.data.Dataset): test dataset.
        &#39;&#39;&#39;
        self.trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, **self.dataloader_params)
        self.testloader = torch.utils.data.DataLoader(testset, shuffle=False, **self.dataloader_params)
        self.trainproducer = infinite_data_batch_producer(self.trainloader)
        

    @abstractmethod
    def train_step(self, backbone: torch.nn.Module) -&gt; bool:
        raise NotImplementedError()
    

    @abstractmethod
    def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
        raise NotImplementedError()


    @abstractmethod
    def reset_optimizers(self):
        raise NotImplementedError()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask">MultiHeadedDatasetTask</a></li>
<li><a title="EdgeEmbedding.emtl.tasks.SimpleTask" href="#EdgeEmbedding.emtl.tasks.SimpleTask">SimpleTask</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.Task.config"><code class="name">var <span class="ident">config</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.device"><code class="name">var <span class="ident">device</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.optimizer_fn"><code class="name">var <span class="ident">optimizer_fn</span> : collections.abc.Callable[..., torch.optim.optimizer.Optimizer]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.testloader"><code class="name">var <span class="ident">testloader</span> : torch.utils.data.dataloader.DataLoader</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.trainloader"><code class="name">var <span class="ident">trainloader</span> : torch.utils.data.dataloader.DataLoader</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="EdgeEmbedding.emtl.tasks.Task.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self, backbone: torch.nn.modules.module.Module, set: str = 'test') ‑> dict[str, float]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def eval(self, backbone: torch.nn.Module, set: str = &#39;test&#39;) -&gt; dict[str, float]:
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders"><code class="name flex">
<span>def <span class="ident">instantiate_dataloaders</span></span>(<span>self, trainset: torch.utils.data.dataset.Dataset, testset: torch.utils.data.dataset.Dataset) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Helper method to create the DataLoaders. This method will also create the train data producer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>trainset</code></strong> :&ensp;<code>torch.utils.data.Dataset</code></dt>
<dd>train dataset.</dd>
<dt><strong><code>testset</code></strong> :&ensp;<code>torch.utils.data.Dataset</code></dt>
<dd>test dataset.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def instantiate_dataloaders(self, trainset: torch.utils.data.Dataset, 
                            testset: torch.utils.data.Dataset) -&gt; None:
    &#39;&#39;&#39;
    Helper method to create the DataLoaders. This method will also create the train data producer.

    Args:
        trainset (torch.utils.data.Dataset): train dataset.
        testset (torch.utils.data.Dataset): test dataset.
    &#39;&#39;&#39;
    self.trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, **self.dataloader_params)
    self.testloader = torch.utils.data.DataLoader(testset, shuffle=False, **self.dataloader_params)
    self.trainproducer = infinite_data_batch_producer(self.trainloader)</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.parse_configurations"><code class="name flex">
<span>def <span class="ident">parse_configurations</span></span>(<span>self, config: str, dataloader_params: dict[str, any], optimizer_params: dict[str, any]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Internal helper method to process a configuration file and method parameters.
This method merges the (optional) configuration within the config file provided (of course,
if any) with the method arguments passed in the function call. When parameters are duplicate,
those passed in the method call take precedence.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>str</code></dt>
<dd>path to a config.ini file</dd>
<dt><strong><code>dataloader_params</code></strong> :&ensp;<code>dict[str, any]</code></dt>
<dd>parameters to pass to the dataloader.</dd>
<dt><strong><code>optimizer_params</code></strong> :&ensp;<code>dict[str, any]</code></dt>
<dd>parameters to pass to the optimizer.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_configurations(self, config: str, dataloader_params: dict[str, any], 
                         optimizer_params: dict[str, any]
                         ) -&gt; None:
    &#39;&#39;&#39;
    Internal helper method to process a configuration file and method parameters.
    This method merges the (optional) configuration within the config file provided (of course,
    if any) with the method arguments passed in the function call. When parameters are duplicate,
    those passed in the method call take precedence.

    Args:
        config (str): path to a config.ini file
        dataloader_params (dict[str, any]): parameters to pass to the dataloader.
        optimizer_params (dict[str, any]): parameters to pass to the optimizer.
    &#39;&#39;&#39;
    parser = ConfigParser()
    parser.read(config)

    # default, possibly empty dictionaries
    self.dataloader_params = config_file_section_to_dict(parser, &#39;dataloader&#39;)
    self.optimizer_params  = config_file_section_to_dict(parser, &#39;optimizer&#39;)
    self.device = parser.get(&#39;global&#39;, &#39;device&#39;, fallback=&#39;cpu&#39;)

    # update values with passed arguments (as they take precedence)
    self.dataloader_params.update(dataloader_params)
    self.optimizer_params.update(optimizer_params)

    # if memory is pinned, then also enable non blocking RAM -&gt; GPU-RAM tranfers
    self.non_blocking_ops = &#39;pin_memory&#39; in self.dataloader_params and self.dataloader_params[&#39;pin_memory&#39;]</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.reset_optimizers"><code class="name flex">
<span>def <span class="ident">reset_optimizers</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def reset_optimizers(self):
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.tasks.Task.train_step"><code class="name flex">
<span>def <span class="ident">train_step</span></span>(<span>self, backbone: torch.nn.modules.module.Module) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def train_step(self, backbone: torch.nn.Module) -&gt; bool:
    raise NotImplementedError()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="EdgeEmbedding.emtl" href="index.html">EdgeEmbedding.emtl</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask">MultiHeadedDatasetTask</a></code></h4>
<ul class="">
<li><code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.eval" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.eval">eval</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.optimizers" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.optimizers">optimizers</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.reset_optimizers" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.reset_optimizers">reset_optimizers</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.tasks_specs" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.tasks_specs">tasks_specs</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.train_step" href="#EdgeEmbedding.emtl.tasks.MultiHeadedDatasetTask.train_step">train_step</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask" href="#EdgeEmbedding.emtl.tasks.SimpleTask">SimpleTask</a></code></h4>
<ul class="two-column">
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.criterion" href="#EdgeEmbedding.emtl.tasks.SimpleTask.criterion">criterion</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.eval" href="#EdgeEmbedding.emtl.tasks.SimpleTask.eval">eval</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.head" href="#EdgeEmbedding.emtl.tasks.SimpleTask.head">head</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.metric_fns" href="#EdgeEmbedding.emtl.tasks.SimpleTask.metric_fns">metric_fns</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.optimizer" href="#EdgeEmbedding.emtl.tasks.SimpleTask.optimizer">optimizer</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.reset_optimizers" href="#EdgeEmbedding.emtl.tasks.SimpleTask.reset_optimizers">reset_optimizers</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.SimpleTask.train_step" href="#EdgeEmbedding.emtl.tasks.SimpleTask.train_step">train_step</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="EdgeEmbedding.emtl.tasks.Task" href="#EdgeEmbedding.emtl.tasks.Task">Task</a></code></h4>
<ul class="">
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.config" href="#EdgeEmbedding.emtl.tasks.Task.config">config</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.device" href="#EdgeEmbedding.emtl.tasks.Task.device">device</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.eval" href="#EdgeEmbedding.emtl.tasks.Task.eval">eval</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders" href="#EdgeEmbedding.emtl.tasks.Task.instantiate_dataloaders">instantiate_dataloaders</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.name" href="#EdgeEmbedding.emtl.tasks.Task.name">name</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.optimizer_fn" href="#EdgeEmbedding.emtl.tasks.Task.optimizer_fn">optimizer_fn</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.parse_configurations" href="#EdgeEmbedding.emtl.tasks.Task.parse_configurations">parse_configurations</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.reset_optimizers" href="#EdgeEmbedding.emtl.tasks.Task.reset_optimizers">reset_optimizers</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.testloader" href="#EdgeEmbedding.emtl.tasks.Task.testloader">testloader</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.train_step" href="#EdgeEmbedding.emtl.tasks.Task.train_step">train_step</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.tasks.Task.trainloader" href="#EdgeEmbedding.emtl.tasks.Task.trainloader">trainloader</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>