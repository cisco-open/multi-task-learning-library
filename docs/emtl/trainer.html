<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>EdgeEmbedding.emtl.trainer API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>EdgeEmbedding.emtl.trainer</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import torch
from configparser import ConfigParser

# inter-class dependencies only for type annotations
from emtl.algorithms import TrainingAlgorithm
from emtl.tasks import Task


class Trainer:
    backbone: torch.nn.Module
    tasks: list[Task]
    use_mlflow: bool
    mlflow_tags: dict[str, any]
    mlflow_params: dict[str, any]
    run_id: str
    epochs_passed: int
    
    def __init__(self, 
                 backbone: torch.nn.Module, 
                 tasks: list[Task], 
                 device: str = None, 
                 use_mlflow: bool = None,
                 config: str = &#39;&#39;,
                 **kwargs
        ) -&gt; None:
        &#39;&#39;&#39;
        Create a coordinator object Trainer.
        Trainer objects are responsible for wrapping together tasks, models, and training algos. 
        The trainer is the one that connects the backbone model to the tasks heads (saving those
        models), and that launches the training of the algorithm, passing in tasks and models.

        Currently a todo feature, the config file allows one to specify parameters for the trainer
        other than through parameters (e.g., tags for the MLFlow run).

        Args:
            backbone (torch.nn.Module): instantiated backbone model to train
            tasks (list[Task]): list of tasks with datasets and specialized heads to train
            algorithm (TrainingAlgorithm): implementation of a training algorithm to consume tasks
            device (str, optional): cpu or cuda:id device to push all classes to. Defaults to &#39;cpu&#39;.
            use_mlflow (bool, optional): set True to use MLFlow (must be installed). Defaults to False.
            config (str, optional): path to a configuration file to replace params. Defaults to &#39;&#39;.
        &#39;&#39;&#39;
        self.tasks = tasks
        self.epochs_passed = 0
        self.run_id = None
        
        # assign instance variables from configuration or parameters (parser empty by default if
        # filepath is not specified, so no errors are thrown, and defaults are returned)
        this_path = os.path.dirname(__file__)
        default_config_path = os.path.join(this_path, os.pardir, &#39;configs&#39;, &#39;trainer&#39;, &#39;default.ini&#39;)

        parser = ConfigParser()
        parser.read(default_config_path)    # default values
        parser.read(config)                 # values from given config file

        # update parser with supplied arguments, if any
        if use_mlflow is not None:      parser.set(&#39;mlflow&#39;, &#39;enabled&#39;, str(use_mlflow))
        if device:                      parser.set(&#39;pytorch&#39;, &#39;device&#39;, device)

        self.use_mlflow = parser.getboolean(&#39;mlflow&#39;, &#39;enabled&#39;)
        device = parser.get(&#39;pytorch&#39;, &#39;device&#39;)

        # save models
        self.backbone = backbone.to(device)

        # connect to MLFlow if it was specified
        if self.use_mlflow:
            self.setup_mlflow(parser, **kwargs)
    

    def setup_mlflow(self, 
                     parser: ConfigParser,
                     mlflow_database: str = None,
                     mlflow_experiment: str = None,
                     mlflow_tags: dict[str, any] = None, 
                     mlflow_params: dict[str, any] = None
        ) -&gt; None:
        &#39;&#39;&#39;
        Setup and connect to an MLFlow instance.
        This method will load an MLFlow database for experiment tracking (or create a new one if the 
        file specified does not exist), and load/create the specified experiment. One can specify
        tags and parameters to attach to the experiment.

        Note: all configurations of this method can be set via programmed parameters or through a
        configuration file.

        Args:
            parser (ConfigParser): loaded parser with default and optional configuration.
            mlflow_database (str, optional): path to the MLFlow DB file. Defaults to &#39;sqlite:///mlflow.db&#39;.
            mlflow_experiment (str, optional): Name of the experiment. Defaults to &#39;Default&#39;.
            mlflow_tags (dict[str, any], optional): dictionary of tags. Defaults to {}.
            mlflow_params (dict[str, any], optional): dictionary of parameters. Defaults to {}.
        &#39;&#39;&#39;
        import mlflow, ast

        # first update parser with any passed arguments
        if mlflow_database:     parser.set(&#39;mlflow&#39;, &#39;database&#39;, mlflow_database)
        if mlflow_experiment:   parser.set(&#39;mlflow&#39;, &#39;experiment&#39;, mlflow_experiment)

        # then, set/use the values
        mlflow.set_tracking_uri(parser.get(&#39;mlflow&#39;, &#39;database&#39;))
        mlflow.set_experiment(parser.get(&#39;mlflow&#39;, &#39;experiment&#39;, fallback=&#39;Default&#39;))
        self.mlflow_tags = mlflow_tags if mlflow_tags else \
            ast.literal_eval(parser.get(&#39;mlflow&#39;, &#39;tags&#39;, fallback=&#39;{}&#39;))
        self.mlflow_params = mlflow_params if mlflow_params else \
            ast.literal_eval(parser.get(&#39;mlflow&#39;, &#39;params&#39;, fallback=&#39;{}&#39;))

    def assert_models_and_tasks_are_valid(self) -&gt; None:
        &#39;&#39;&#39;
        Sanity check to make sure data from the tasks&#39; loader can go through the backbone &amp; heads.
        More rigorous testing would require passing in the input and output shapes at execution time,
        which is not user-friendly.
        &#39;&#39;&#39;
        # to test that models and tasks work as expected, for a sanity check, let&#39;s make one fw pass
        with torch.no_grad():
            for task in self.tasks:
                # train set
                (inputs, _), _ = next(task.train_producer())
                features = self.backbone(inputs)
                task.head(features)
                
                # test set
                (inputs, _), _ = next(task.test_producer())
                features = self.backbone(inputs)
                task.head(features)
    
    def launch(self, algorithm: TrainingAlgorithm, run_id: str = None, reset_optimizers: bool = True) -&gt; str:
        &#39;&#39;&#39;
        Launch the training algorithm, optionally in a new MLFLow session (whose ID is returned).

        Args:
            run_id (str, optional): can reuse an existing MLFlow run. Defaults to None.

        Returns:
            str: the run ID of this MLFlow experiment (if any).
        &#39;&#39;&#39;
        if reset_optimizers:
            algorithm.reset_optimizers(self.backbone)
            
            for task in self.tasks:
                task.reset_optimizers()

        # MLFlow is disabled
        if not self.use_mlflow:
            epochs = algorithm.execute(self.backbone, self.tasks, self.epochs_passed)
            self.epochs_passed += epochs
            return

        # MLFLow is enabled, and there may be problems, so we need to close the run anyways
        try:
            import mlflow

            # use the specified run_id if supplied, otherwise resume the previous run, if it exists
            run_id = run_id if run_id else self.run_id

            with mlflow.start_run(run_id=run_id, tags=self.mlflow_tags) as run:
                mlflow.log_params(self.mlflow_params)
                epochs = algorithm.execute(self.backbone, self.tasks, self.epochs_passed)
                self.epochs_passed += epochs
                self.run_id = run.info.run_id
                return run.info.run_id

        except Exception:
            mlflow.end_run()
            raise</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="EdgeEmbedding.emtl.trainer.Trainer"><code class="flex name class">
<span>class <span class="ident">Trainer</span></span>
<span>(</span><span>backbone: torch.nn.modules.module.Module, tasks: list[emtl.tasks.Task], device: str = None, use_mlflow: bool = None, config: str = '', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a coordinator object Trainer.
Trainer objects are responsible for wrapping together tasks, models, and training algos.
The trainer is the one that connects the backbone model to the tasks heads (saving those
models), and that launches the training of the algorithm, passing in tasks and models.</p>
<p>Currently a todo feature, the config file allows one to specify parameters for the trainer
other than through parameters (e.g., tags for the MLFlow run).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>backbone</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>instantiated backbone model to train</dd>
<dt><strong><code>tasks</code></strong> :&ensp;<code>list[Task]</code></dt>
<dd>list of tasks with datasets and specialized heads to train</dd>
<dt><strong><code>algorithm</code></strong> :&ensp;<code>TrainingAlgorithm</code></dt>
<dd>implementation of a training algorithm to consume tasks</dd>
<dt><strong><code>device</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>cpu or cuda:id device to push all classes to. Defaults to 'cpu'.</dd>
<dt><strong><code>use_mlflow</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>set True to use MLFlow (must be installed). Defaults to False.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>path to a configuration file to replace params. Defaults to ''.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Trainer:
    backbone: torch.nn.Module
    tasks: list[Task]
    use_mlflow: bool
    mlflow_tags: dict[str, any]
    mlflow_params: dict[str, any]
    run_id: str
    epochs_passed: int
    
    def __init__(self, 
                 backbone: torch.nn.Module, 
                 tasks: list[Task], 
                 device: str = None, 
                 use_mlflow: bool = None,
                 config: str = &#39;&#39;,
                 **kwargs
        ) -&gt; None:
        &#39;&#39;&#39;
        Create a coordinator object Trainer.
        Trainer objects are responsible for wrapping together tasks, models, and training algos. 
        The trainer is the one that connects the backbone model to the tasks heads (saving those
        models), and that launches the training of the algorithm, passing in tasks and models.

        Currently a todo feature, the config file allows one to specify parameters for the trainer
        other than through parameters (e.g., tags for the MLFlow run).

        Args:
            backbone (torch.nn.Module): instantiated backbone model to train
            tasks (list[Task]): list of tasks with datasets and specialized heads to train
            algorithm (TrainingAlgorithm): implementation of a training algorithm to consume tasks
            device (str, optional): cpu or cuda:id device to push all classes to. Defaults to &#39;cpu&#39;.
            use_mlflow (bool, optional): set True to use MLFlow (must be installed). Defaults to False.
            config (str, optional): path to a configuration file to replace params. Defaults to &#39;&#39;.
        &#39;&#39;&#39;
        self.tasks = tasks
        self.epochs_passed = 0
        self.run_id = None
        
        # assign instance variables from configuration or parameters (parser empty by default if
        # filepath is not specified, so no errors are thrown, and defaults are returned)
        this_path = os.path.dirname(__file__)
        default_config_path = os.path.join(this_path, os.pardir, &#39;configs&#39;, &#39;trainer&#39;, &#39;default.ini&#39;)

        parser = ConfigParser()
        parser.read(default_config_path)    # default values
        parser.read(config)                 # values from given config file

        # update parser with supplied arguments, if any
        if use_mlflow is not None:      parser.set(&#39;mlflow&#39;, &#39;enabled&#39;, str(use_mlflow))
        if device:                      parser.set(&#39;pytorch&#39;, &#39;device&#39;, device)

        self.use_mlflow = parser.getboolean(&#39;mlflow&#39;, &#39;enabled&#39;)
        device = parser.get(&#39;pytorch&#39;, &#39;device&#39;)

        # save models
        self.backbone = backbone.to(device)

        # connect to MLFlow if it was specified
        if self.use_mlflow:
            self.setup_mlflow(parser, **kwargs)
    

    def setup_mlflow(self, 
                     parser: ConfigParser,
                     mlflow_database: str = None,
                     mlflow_experiment: str = None,
                     mlflow_tags: dict[str, any] = None, 
                     mlflow_params: dict[str, any] = None
        ) -&gt; None:
        &#39;&#39;&#39;
        Setup and connect to an MLFlow instance.
        This method will load an MLFlow database for experiment tracking (or create a new one if the 
        file specified does not exist), and load/create the specified experiment. One can specify
        tags and parameters to attach to the experiment.

        Note: all configurations of this method can be set via programmed parameters or through a
        configuration file.

        Args:
            parser (ConfigParser): loaded parser with default and optional configuration.
            mlflow_database (str, optional): path to the MLFlow DB file. Defaults to &#39;sqlite:///mlflow.db&#39;.
            mlflow_experiment (str, optional): Name of the experiment. Defaults to &#39;Default&#39;.
            mlflow_tags (dict[str, any], optional): dictionary of tags. Defaults to {}.
            mlflow_params (dict[str, any], optional): dictionary of parameters. Defaults to {}.
        &#39;&#39;&#39;
        import mlflow, ast

        # first update parser with any passed arguments
        if mlflow_database:     parser.set(&#39;mlflow&#39;, &#39;database&#39;, mlflow_database)
        if mlflow_experiment:   parser.set(&#39;mlflow&#39;, &#39;experiment&#39;, mlflow_experiment)

        # then, set/use the values
        mlflow.set_tracking_uri(parser.get(&#39;mlflow&#39;, &#39;database&#39;))
        mlflow.set_experiment(parser.get(&#39;mlflow&#39;, &#39;experiment&#39;, fallback=&#39;Default&#39;))
        self.mlflow_tags = mlflow_tags if mlflow_tags else \
            ast.literal_eval(parser.get(&#39;mlflow&#39;, &#39;tags&#39;, fallback=&#39;{}&#39;))
        self.mlflow_params = mlflow_params if mlflow_params else \
            ast.literal_eval(parser.get(&#39;mlflow&#39;, &#39;params&#39;, fallback=&#39;{}&#39;))

    def assert_models_and_tasks_are_valid(self) -&gt; None:
        &#39;&#39;&#39;
        Sanity check to make sure data from the tasks&#39; loader can go through the backbone &amp; heads.
        More rigorous testing would require passing in the input and output shapes at execution time,
        which is not user-friendly.
        &#39;&#39;&#39;
        # to test that models and tasks work as expected, for a sanity check, let&#39;s make one fw pass
        with torch.no_grad():
            for task in self.tasks:
                # train set
                (inputs, _), _ = next(task.train_producer())
                features = self.backbone(inputs)
                task.head(features)
                
                # test set
                (inputs, _), _ = next(task.test_producer())
                features = self.backbone(inputs)
                task.head(features)
    
    def launch(self, algorithm: TrainingAlgorithm, run_id: str = None, reset_optimizers: bool = True) -&gt; str:
        &#39;&#39;&#39;
        Launch the training algorithm, optionally in a new MLFLow session (whose ID is returned).

        Args:
            run_id (str, optional): can reuse an existing MLFlow run. Defaults to None.

        Returns:
            str: the run ID of this MLFlow experiment (if any).
        &#39;&#39;&#39;
        if reset_optimizers:
            algorithm.reset_optimizers(self.backbone)
            
            for task in self.tasks:
                task.reset_optimizers()

        # MLFlow is disabled
        if not self.use_mlflow:
            epochs = algorithm.execute(self.backbone, self.tasks, self.epochs_passed)
            self.epochs_passed += epochs
            return

        # MLFLow is enabled, and there may be problems, so we need to close the run anyways
        try:
            import mlflow

            # use the specified run_id if supplied, otherwise resume the previous run, if it exists
            run_id = run_id if run_id else self.run_id

            with mlflow.start_run(run_id=run_id, tags=self.mlflow_tags) as run:
                mlflow.log_params(self.mlflow_params)
                epochs = algorithm.execute(self.backbone, self.tasks, self.epochs_passed)
                self.epochs_passed += epochs
                self.run_id = run.info.run_id
                return run.info.run_id

        except Exception:
            mlflow.end_run()
            raise</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.backbone"><code class="name">var <span class="ident">backbone</span> : torch.nn.modules.module.Module</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.epochs_passed"><code class="name">var <span class="ident">epochs_passed</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.mlflow_params"><code class="name">var <span class="ident">mlflow_params</span> : dict[str, any]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.mlflow_tags"><code class="name">var <span class="ident">mlflow_tags</span> : dict[str, any]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.run_id"><code class="name">var <span class="ident">run_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.tasks"><code class="name">var <span class="ident">tasks</span> : list[emtl.tasks.Task]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.use_mlflow"><code class="name">var <span class="ident">use_mlflow</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.assert_models_and_tasks_are_valid"><code class="name flex">
<span>def <span class="ident">assert_models_and_tasks_are_valid</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Sanity check to make sure data from the tasks' loader can go through the backbone &amp; heads.
More rigorous testing would require passing in the input and output shapes at execution time,
which is not user-friendly.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assert_models_and_tasks_are_valid(self) -&gt; None:
    &#39;&#39;&#39;
    Sanity check to make sure data from the tasks&#39; loader can go through the backbone &amp; heads.
    More rigorous testing would require passing in the input and output shapes at execution time,
    which is not user-friendly.
    &#39;&#39;&#39;
    # to test that models and tasks work as expected, for a sanity check, let&#39;s make one fw pass
    with torch.no_grad():
        for task in self.tasks:
            # train set
            (inputs, _), _ = next(task.train_producer())
            features = self.backbone(inputs)
            task.head(features)
            
            # test set
            (inputs, _), _ = next(task.test_producer())
            features = self.backbone(inputs)
            task.head(features)</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.launch"><code class="name flex">
<span>def <span class="ident">launch</span></span>(<span>self, algorithm: emtl.algorithms.TrainingAlgorithm, run_id: str = None, reset_optimizers: bool = True) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Launch the training algorithm, optionally in a new MLFLow session (whose ID is returned).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>run_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>can reuse an existing MLFlow run. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>the run ID of this MLFlow experiment (if any).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def launch(self, algorithm: TrainingAlgorithm, run_id: str = None, reset_optimizers: bool = True) -&gt; str:
    &#39;&#39;&#39;
    Launch the training algorithm, optionally in a new MLFLow session (whose ID is returned).

    Args:
        run_id (str, optional): can reuse an existing MLFlow run. Defaults to None.

    Returns:
        str: the run ID of this MLFlow experiment (if any).
    &#39;&#39;&#39;
    if reset_optimizers:
        algorithm.reset_optimizers(self.backbone)
        
        for task in self.tasks:
            task.reset_optimizers()

    # MLFlow is disabled
    if not self.use_mlflow:
        epochs = algorithm.execute(self.backbone, self.tasks, self.epochs_passed)
        self.epochs_passed += epochs
        return

    # MLFLow is enabled, and there may be problems, so we need to close the run anyways
    try:
        import mlflow

        # use the specified run_id if supplied, otherwise resume the previous run, if it exists
        run_id = run_id if run_id else self.run_id

        with mlflow.start_run(run_id=run_id, tags=self.mlflow_tags) as run:
            mlflow.log_params(self.mlflow_params)
            epochs = algorithm.execute(self.backbone, self.tasks, self.epochs_passed)
            self.epochs_passed += epochs
            self.run_id = run.info.run_id
            return run.info.run_id

    except Exception:
        mlflow.end_run()
        raise</code></pre>
</details>
</dd>
<dt id="EdgeEmbedding.emtl.trainer.Trainer.setup_mlflow"><code class="name flex">
<span>def <span class="ident">setup_mlflow</span></span>(<span>self, parser: configparser.ConfigParser, mlflow_database: str = None, mlflow_experiment: str = None, mlflow_tags: dict[str, any] = None, mlflow_params: dict[str, any] = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Setup and connect to an MLFlow instance.
This method will load an MLFlow database for experiment tracking (or create a new one if the
file specified does not exist), and load/create the specified experiment. One can specify
tags and parameters to attach to the experiment.</p>
<p>Note: all configurations of this method can be set via programmed parameters or through a
configuration file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>parser</code></strong> :&ensp;<code>ConfigParser</code></dt>
<dd>loaded parser with default and optional configuration.</dd>
<dt><strong><code>mlflow_database</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>path to the MLFlow DB file. Defaults to 'sqlite:///mlflow.db'.</dd>
<dt><strong><code>mlflow_experiment</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of the experiment. Defaults to 'Default'.</dd>
<dt><strong><code>mlflow_tags</code></strong> :&ensp;<code>dict[str, any]</code>, optional</dt>
<dd>dictionary of tags. Defaults to {}.</dd>
<dt><strong><code>mlflow_params</code></strong> :&ensp;<code>dict[str, any]</code>, optional</dt>
<dd>dictionary of parameters. Defaults to {}.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup_mlflow(self, 
                 parser: ConfigParser,
                 mlflow_database: str = None,
                 mlflow_experiment: str = None,
                 mlflow_tags: dict[str, any] = None, 
                 mlflow_params: dict[str, any] = None
    ) -&gt; None:
    &#39;&#39;&#39;
    Setup and connect to an MLFlow instance.
    This method will load an MLFlow database for experiment tracking (or create a new one if the 
    file specified does not exist), and load/create the specified experiment. One can specify
    tags and parameters to attach to the experiment.

    Note: all configurations of this method can be set via programmed parameters or through a
    configuration file.

    Args:
        parser (ConfigParser): loaded parser with default and optional configuration.
        mlflow_database (str, optional): path to the MLFlow DB file. Defaults to &#39;sqlite:///mlflow.db&#39;.
        mlflow_experiment (str, optional): Name of the experiment. Defaults to &#39;Default&#39;.
        mlflow_tags (dict[str, any], optional): dictionary of tags. Defaults to {}.
        mlflow_params (dict[str, any], optional): dictionary of parameters. Defaults to {}.
    &#39;&#39;&#39;
    import mlflow, ast

    # first update parser with any passed arguments
    if mlflow_database:     parser.set(&#39;mlflow&#39;, &#39;database&#39;, mlflow_database)
    if mlflow_experiment:   parser.set(&#39;mlflow&#39;, &#39;experiment&#39;, mlflow_experiment)

    # then, set/use the values
    mlflow.set_tracking_uri(parser.get(&#39;mlflow&#39;, &#39;database&#39;))
    mlflow.set_experiment(parser.get(&#39;mlflow&#39;, &#39;experiment&#39;, fallback=&#39;Default&#39;))
    self.mlflow_tags = mlflow_tags if mlflow_tags else \
        ast.literal_eval(parser.get(&#39;mlflow&#39;, &#39;tags&#39;, fallback=&#39;{}&#39;))
    self.mlflow_params = mlflow_params if mlflow_params else \
        ast.literal_eval(parser.get(&#39;mlflow&#39;, &#39;params&#39;, fallback=&#39;{}&#39;))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="EdgeEmbedding.emtl" href="index.html">EdgeEmbedding.emtl</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="EdgeEmbedding.emtl.trainer.Trainer" href="#EdgeEmbedding.emtl.trainer.Trainer">Trainer</a></code></h4>
<ul class="">
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.assert_models_and_tasks_are_valid" href="#EdgeEmbedding.emtl.trainer.Trainer.assert_models_and_tasks_are_valid">assert_models_and_tasks_are_valid</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.backbone" href="#EdgeEmbedding.emtl.trainer.Trainer.backbone">backbone</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.epochs_passed" href="#EdgeEmbedding.emtl.trainer.Trainer.epochs_passed">epochs_passed</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.launch" href="#EdgeEmbedding.emtl.trainer.Trainer.launch">launch</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.mlflow_params" href="#EdgeEmbedding.emtl.trainer.Trainer.mlflow_params">mlflow_params</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.mlflow_tags" href="#EdgeEmbedding.emtl.trainer.Trainer.mlflow_tags">mlflow_tags</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.run_id" href="#EdgeEmbedding.emtl.trainer.Trainer.run_id">run_id</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.setup_mlflow" href="#EdgeEmbedding.emtl.trainer.Trainer.setup_mlflow">setup_mlflow</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.tasks" href="#EdgeEmbedding.emtl.trainer.Trainer.tasks">tasks</a></code></li>
<li><code><a title="EdgeEmbedding.emtl.trainer.Trainer.use_mlflow" href="#EdgeEmbedding.emtl.trainer.Trainer.use_mlflow">use_mlflow</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>